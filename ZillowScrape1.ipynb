{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af436e92-1bae-4fdf-b676-520701150f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c35f7ec-8243-48ea-818a-f6fe75cfbf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea9fd8c-db98-4553-a95e-3da36ceccc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bed</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Hsize</th>\n",
       "      <th>Land_Size</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299999</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1248</td>\n",
       "      <td>43560.0</td>\n",
       "      <td>Rensselaer</td>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Bed  Bath  Hsize  Land_Size        City    State\n",
       "0  299999    3     2   1248    43560.0  Rensselaer  Indiana"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.zillow.com/homedetails/229-W-Wood-Rd-Rensselaer-IN-47978/85412995_zpid/'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    \"Referer\": \"https://google.com\",\n",
    "    \"DNT\": \"1\",\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "session = requests.Session()\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "State_abbreviations = {\n",
    "    'AL': 'Alabama','AK': 'Alaska','AZ': 'Arizona','AR': 'Arkansas','CA': 'California','CO': 'Colorado','CT': 'Connecticut','DE': 'Delaware','FL': 'Florida',\n",
    "    'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho','IL': 'Illinois','IN': 'Indiana','IA': 'Iowa','KS': 'Kansas','KY': 'Kentucky','LA': 'Louisiana','ME': 'Maine','MD': 'Maryland',\n",
    "    'MA': 'Massachusetts','MI': 'Michigan','MN': 'Minnesota','MS': 'Mississippi','MO': 'Missouri','MT': 'Montana','NE': 'Nebraska','NV': 'Nevada',\n",
    "    'NH': 'New Hampshire','NJ': 'New Jersey','NM': 'New Mexico','NY': 'New York','NC': 'North Carolina','ND': 'North Dakota','OH': 'Ohio','OK': 'Oklahoma',\n",
    "    'OR': 'Oregon','PA': 'Pennsylvania','RI': 'Rhode Island','SC': 'South Carolina','SD': 'South Dakota','TN': 'Tennessee','TX': 'Texas','UT': 'Utah','VT': 'Vermont',\n",
    "    'VA': 'Virginia','WA': 'Washington','WV': 'West Virginia','WI': 'Wisconsin','WY': 'Wyoming','DC': 'District of Columbia'\n",
    "}\n",
    "\n",
    "def Property_Info(url): \n",
    "\n",
    "    #Scraping price \n",
    "    def Hprice(url):\n",
    "    \n",
    "        #Scraping the price from the website and converting it to a integer \n",
    "        found_price = None\n",
    "    \n",
    "        # STRATEGY 1: (Data ID)\n",
    "        # Zillow often leaves this attribute alone even when they change CSS classes.\n",
    "        # This is the most reliable method for active listings.\n",
    "        if not found_price:\n",
    "            element = soup.find('span', {'data-testid': 'price'})\n",
    "            if element:\n",
    "                found_price = element.get_text(strip=True)\n",
    "        \n",
    "        # STRATEGY 2: Partial Class Match (The \"Smart\" Search)\n",
    "        # We look for ANY <span> where the class name STARTS with \"Text-c11n\"\n",
    "        if not found_price:\n",
    "            # re.compile(r'^Text-c11n') means: Starts with \"Text-c11n\"\n",
    "            potential_prices = soup.find_all('span', class_=re.compile(r'^Text-c11n'))\n",
    "            \n",
    "            for element in potential_prices:\n",
    "                text = element.get_text(strip=True)\n",
    "                # Validation: Is this actually a price?\n",
    "                # It must start with '$', contain digits, and be short (e.g. \"$549,900\")\n",
    "                if text.startswith('$') and any(char.isdigit() for char in text) and len(text) < 20:\n",
    "                    found_price = text\n",
    "                    break\n",
    "        \n",
    "        # STRATEGY 3: Keyword Match\n",
    "        # Look for ANY tag that has the word \"price\" anywhere in its class name.\n",
    "        if not found_price:\n",
    "            # re.I means Case Insensitive (matches \"Price\", \"price\", \"PRICE\")\n",
    "            price_tags = soup.find_all(['div', 'span'], class_=re.compile(r'price', re.I))\n",
    "            \n",
    "            for element in price_tags:\n",
    "                text = element.get_text(strip=True)\n",
    "                if '$' in text and any(char.isdigit() for char in text) and len(text) < 20: \n",
    "                    found_price = text\n",
    "                    break\n",
    "        \n",
    "        # STRATEGY 4: The \"Nuclear\" Option (JSON Search)\n",
    "        # If HTML fails, we scan the raw background code for the \"price\" variable.\n",
    "        if not found_price:\n",
    "            # Look for patterns like \"price\":549900 or \"amount\":549900 in the scripts\n",
    "            patterns = [\n",
    "                r'\"price\":(\\d+),',\n",
    "                r'\"amount\":(\\d+),'\n",
    "            ]\n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, str(soup))\n",
    "                if match:\n",
    "                    found_price = f\"${int(match.group(1)):,}\"\n",
    "                    break\n",
    "        \n",
    "        # 5. Final Result Handling\n",
    "        if not found_price:\n",
    "            found_price = \"Price not found (Likely Off-Market or Captcha)\"\n",
    "        \n",
    "        final_price = int(found_price.replace('$', '').replace(',', ''))\n",
    "        return final_price\n",
    "\n",
    "    \n",
    "#scraping bed, bath, housing size    \n",
    "    def extract_bed_bath_hsize(url):\n",
    "    \n",
    "        facts = {\n",
    "                'beds': 'N/A', \n",
    "                'baths': 'N/A',\n",
    "                'sqft': 'N/A'\n",
    "            }\n",
    "        body_text = soup.get_text().replace(',', '').lower() \n",
    "            \n",
    "        def find_fact(text, pattern):\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "            return 'N/A'\n",
    "        \n",
    "        # look for a number (1 or 2 digits, {1}) right before 'beds'. \n",
    "        facts['beds'] = find_fact(body_text, r'(\\d{1})\\s*(bed|beds)')\n",
    "        \n",
    "        # 2. Search for Baths: A number .\n",
    "        facts['baths'] = find_fact(body_text, r'(\\d+\\.?\\d*)\\s*(bath|baths)')\n",
    "        \n",
    "        # 3. Search for SqFt: A number (often 3-5 digits) before 'sqft'.\n",
    "        facts['sqft'] = find_fact(body_text, r'(\\d+)\\s*sqft')\n",
    "    \n",
    "        final_list = [\n",
    "                int(facts['beds']) if facts['beds'] != 'N/A' else facts['beds'],          \n",
    "                int(facts['baths']) if facts['baths'] != 'N/A' else facts['baths'],\n",
    "                int(facts['sqft']) if facts['sqft'] != 'N/A' else facts['sqft']\n",
    "            ]\n",
    "        \n",
    "        return final_list\n",
    "    \n",
    "    size_regex = re.compile(r'([\\d,\\.]+)\\s*(Acres|lot|sqft)', re.IGNORECASE)\n",
    "    Land = soup.find_all('span', string=size_regex)\n",
    "        \n",
    "    def land_sizeft(Lands):\n",
    "        land_size_sqft = None \n",
    "                   \n",
    "        for element in Land:\n",
    "            text = element.text.strip()\n",
    "            # \"-- sqft\" check\n",
    "            if not Land:\n",
    "                return None\n",
    "        \n",
    "            # # if sqft or acres check ()\n",
    "            sqft_match = re.match(r\"([\\d,.]+)\\s*(Square Feet|sqft)\", text, re.IGNORECASE)\n",
    "            acre_match = re.match(r\"([\\d,.]+)\\s*Acres\", text, re.IGNORECASE)\n",
    "        \n",
    "            if sqft_match:\n",
    "                land_size_sqft = float(sqft_match.group(1).replace(\",\", \"\"))\n",
    "                \n",
    "            elif acre_match:\n",
    "                acres = float(acre_match.group(1))\n",
    "                land_size_sqft = round(acres * 43560, 2)\n",
    "            \n",
    "            if land_size_sqft is not None:\n",
    "                 break \n",
    "                     \n",
    "        return land_size_sqft\n",
    "        \n",
    "\n",
    "    \n",
    "        #Scraping the city\n",
    "    address = (soup.find_all('h1')[0]).text\n",
    "    def get_city(addresses):\n",
    "        address1 = address.replace('\\xa0', '')\n",
    "        split_address = address1.split(',')\n",
    "        state_zip = split_address[-1].strip()\n",
    "        state_abbr = state_zip.split()[0]\n",
    "        state_full = State_abbreviations.get(state_abbr, \"Unknown State\")\n",
    "        city = split_address[1]\n",
    "\n",
    "        return city, state_full\n",
    "        \n",
    "    data_list = []\n",
    "    Property_Dict =  {\n",
    "            'Price': Hprice(url),\n",
    "            'Bed': (extract_bed_bath_hsize(soup))[0],\n",
    "            'Bath': (extract_bed_bath_hsize(soup))[1],\n",
    "            'Hsize': (extract_bed_bath_hsize(soup))[2], \n",
    "            'Land_Size': land_sizeft(Land), \n",
    "            'City': (get_city(address))[0],\n",
    "            'State': (get_city(address))[1] }\n",
    "\n",
    "    data_list.append(Property_Dict)\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df\n",
    "\n",
    "\n",
    "Property_Info(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
